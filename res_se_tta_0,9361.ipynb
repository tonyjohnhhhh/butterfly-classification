{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8780816,"sourceType":"datasetVersion","datasetId":3442424},{"sourceId":10493904,"sourceType":"datasetVersion","datasetId":6497308}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## A Simple CNN Baseline Using Pretrained ResNet18\nAuthor: Junye Wang (群柴犬@DataTech工作室)","metadata":{}},{"cell_type":"markdown","source":"### 导入必要的库工具","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import balanced_accuracy_score\nfrom PIL import Image\nfrom tqdm import tqdm\nimport numpy as np\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:17.965679Z","iopub.execute_input":"2025-02-05T10:10:17.965959Z","iopub.status.idle":"2025-02-05T10:10:24.963801Z","shell.execute_reply.started":"2025-02-05T10:10:17.965928Z","shell.execute_reply":"2025-02-05T10:10:24.963150Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### 适配竞赛服务器的文件路径","metadata":{}},{"cell_type":"code","source":"DATASET_PATH = '/kaggle/input/the-1st-datatech-alchemist-cup-public-dataset'\nTRAIN_CSV = os.path.join(DATASET_PATH, 'train.csv')\nTEST_CSV = os.path.join(DATASET_PATH, 'test.csv')\nTRAIN_IMAGES = os.path.join(DATASET_PATH, 'train_images')\nTEST_IMAGES = os.path.join(DATASET_PATH, 'test_images')\nSUBMISSION_FILE = '/kaggle/working/submission.csv'\n\n# DATASET_PATH = '/kaggle/input/butterfly-image-classification'\n# TRAIN_CSV = os.path.join(DATASET_PATH, 'Training_set.csv')\n# TEST_CSV = os.path.join(DATASET_PATH, 'Testing_set.csv')\n# TRAIN_IMAGES = os.path.join(DATASET_PATH, 'train')\n# TEST_IMAGES = os.path.join(DATASET_PATH, 'test')\n# SUBMISSION_FILE = '/kaggle/working/submission.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:24.964612Z","iopub.execute_input":"2025-02-05T10:10:24.965080Z","iopub.status.idle":"2025-02-05T10:10:24.969086Z","shell.execute_reply.started":"2025-02-05T10:10:24.965024Z","shell.execute_reply":"2025-02-05T10:10:24.968132Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### 定义超参数","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nEPOCHS = 100\nLEARNING_RATE = 0.001\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:24.969786Z","iopub.execute_input":"2025-02-05T10:10:24.970108Z","iopub.status.idle":"2025-02-05T10:10:25.037019Z","shell.execute_reply.started":"2025-02-05T10:10:24.970081Z","shell.execute_reply":"2025-02-05T10:10:25.036372Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def load_csv():\n    train_df = pd.read_csv(TRAIN_CSV)\n    test_df = pd.read_csv(TEST_CSV)\n    labels = train_df['label'].unique().tolist()\n    label_to_idx = {label: idx for idx, label in enumerate(labels)}\n    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n    return train_df, test_df, label_to_idx, idx_to_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:25.039143Z","iopub.execute_input":"2025-02-05T10:10:25.039409Z","iopub.status.idle":"2025-02-05T10:10:25.044819Z","shell.execute_reply.started":"2025-02-05T10:10:25.039375Z","shell.execute_reply":"2025-02-05T10:10:25.044005Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### 自定义数据集类","metadata":{}},{"cell_type":"code","source":"class ButterflyDataset(Dataset):\n    def __init__(self, dataframe, image_dir, label_to_idx=None, transform=None):\n        self.dataframe = dataframe\n        self.image_dir = image_dir\n        self.label_to_idx = label_to_idx\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = self.dataframe.iloc[idx, 0]\n        img_path = os.path.join(self.image_dir, img_name)\n        image = Image.open(img_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.label_to_idx:\n            label = self.dataframe.iloc[idx, 1]\n            label = self.label_to_idx[label]\n            return image, label\n        else:\n            return image, img_name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:25.046270Z","iopub.execute_input":"2025-02-05T10:10:25.046555Z","iopub.status.idle":"2025-02-05T10:10:25.059551Z","shell.execute_reply.started":"2025-02-05T10:10:25.046534Z","shell.execute_reply":"2025-02-05T10:10:25.058808Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### 数据增强与预处理","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms.v2\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntrain_transform = transforms.Compose([\n    # transforms.Resize((256, 256)),\n    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # 随机裁剪\n    # transforms.RandomHorizontalFlip(p=0.5),              # 水平翻转\n    # transforms.RandomRotation(15),                       # 随机旋转\n    # transforms.ToTensor(),\n    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n    transforms.v2.RandAugment(num_ops = 3, magnitude = 9),  # RandAugment\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(45),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n    transforms.RandomPerspective(distortion_scale=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2))  # 随机擦除\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:25.060204Z","iopub.execute_input":"2025-02-05T10:10:25.060408Z","iopub.status.idle":"2025-02-05T10:10:25.160952Z","shell.execute_reply.started":"2025-02-05T10:10:25.060390Z","shell.execute_reply":"2025-02-05T10:10:25.160108Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def rand_bbox(size, lam):\n    \"\"\" 生成随机裁剪的边界框 \"\"\"\n    W, H = size[2], size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\ndef cutmix_data(x, y, alpha):\n    \"\"\" 执行CutMix增强 \"\"\"\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n\n    # 生成混合图像\n    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n    \n    # 调整lambda值（根据实际裁剪区域比例）\n    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n    \n    # 混合标签\n    y_a, y_b = y, y[index]\n    return x, y_a, y_b, lam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:25.161867Z","iopub.execute_input":"2025-02-05T10:10:25.162130Z","iopub.status.idle":"2025-02-05T10:10:25.168790Z","shell.execute_reply.started":"2025-02-05T10:10:25.162109Z","shell.execute_reply":"2025-02-05T10:10:25.168055Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### 载入数据","metadata":{}},{"cell_type":"code","source":"# 修改数据加载部分\ntrain_df, test_df, label_to_idx, idx_to_label = load_csv()\n\n# 划分训练集和验证集\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n\n# 创建数据集\ntrain_dataset = ButterflyDataset(train_df, TRAIN_IMAGES, label_to_idx, train_transform)\nval_dataset = ButterflyDataset(val_df, TRAIN_IMAGES, label_to_idx, transform)\ntest_dataset = ButterflyDataset(test_df, TEST_IMAGES, transform=transform)\n\n# 创建数据加载器\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:25.169678Z","iopub.execute_input":"2025-02-05T10:10:25.169970Z","iopub.status.idle":"2025-02-05T10:10:25.232668Z","shell.execute_reply.started":"2025-02-05T10:10:25.169941Z","shell.execute_reply":"2025-02-05T10:10:25.232045Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"设计一个 CNN 模型的 class","metadata":{}},{"cell_type":"code","source":"# class ButterflyCNN(nn.Module):\n#     def __init__(self, num_classes):\n#         super(ButterflyCNN, self).__init__()\n#         self.model = models.resnet18(pretrained=True)\n#         self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n               \n#         for param in self.model.parameters():\n#             param.requires_grad = False\n        \n#         for param in self.model.layer4.parameters():\n#             param.requires_grad = True\n#         for param in self.model.fc.parameters():\n#             param.requires_grad = True\n            \n#         # 添加Dropout层\n#         self.model.fc = nn.Sequential(\n#             nn.Dropout(0.5),  \n#             nn.Linear(self.model.fc.in_features, num_classes)\n#         )\n\n#     def forward(self, x):\n#         return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:25.233315Z","iopub.execute_input":"2025-02-05T10:10:25.233511Z","iopub.status.idle":"2025-02-05T10:10:25.237218Z","shell.execute_reply.started":"2025-02-05T10:10:25.233494Z","shell.execute_reply":"2025-02-05T10:10:25.236155Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### 实例化待训练模型，载入预训练的 Resnet18 卷积神经网络","metadata":{}},{"cell_type":"markdown","source":"### 设计 Loss 函数和优化器","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models as models\nimport types\n\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport types\n\n# 定义CBAM模块（通道注意力和空间注意力）\nclass CBAM(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super().__init__()\n        # 通道注意力\n        self.channel_att = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(channel, channel//reduction, 1),\n            nn.ReLU(),\n            nn.Conv2d(channel//reduction, channel, 1),\n            nn.Sigmoid()\n        )\n        # 空间注意力\n        self.spatial_att = nn.Sequential(\n            nn.Conv2d(2, 1, 7, padding=3),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # 通道注意力\n        channel_att = self.channel_att(x)\n        x_channel = x * channel_att\n        \n        # 空间注意力\n        avg_out = torch.mean(x_channel, dim=1, keepdim=True)\n        max_out, _ = torch.max(x_channel, dim=1, keepdim=True)\n        spatial_att = self.spatial_att(torch.cat([avg_out, max_out], dim=1))\n        return x_channel * spatial_att\n\nclass ButterflyCNN(nn.Module):\n    def __init__(self, num_classes, dropout_rate=0.5):\n        super(ButterflyCNN, self).__init__()\n        self.model = models.resnet50(pretrained=True)\n        \n        # Unfreeze specific layers\n        for name, param in self.model.named_parameters():\n            if \"layer3\" in name or \"layer4\" in name or \"layer2\" in name:\n                param.requires_grad = True\n            else:\n                param.requires_grad = False\n        \n        # Insert CBAM into ResNet blocks\n        def insert_attention(block):\n            original_forward = block.forward\n    \n            def new_forward(self, x):\n                identity = x\n                out = self.conv1(x)\n                out = self.bn1(out)\n                out = self.relu(out)\n                \n                out = self.conv2(out)\n                out = self.bn2(out)\n                \n                if hasattr(self, 'attention'):\n                    out = self.attention(out)\n                \n                if self.downsample is not None:\n                    identity = self.downsample(x)\n                out += identity\n                out = self.relu(out)\n                return out\n    \n            channel = block.conv2.out_channels\n            block.attention = CBAM(channel)\n            block.forward = types.MethodType(new_forward, block)\n        \n        # Apply CBAM to layer3 and layer4\n        for block in self.model.layer3.children():\n            if isinstance(block, models.resnet.BasicBlock):\n                insert_attention(block)\n        for block in self.model.layer4.children():\n            if isinstance(block, models.resnet.BasicBlock):\n                insert_attention(block)\n        \n        # Corrected classification head\n        self.model.fc = nn.Sequential(\n            nn.Linear(2048, 1024),  # Input features from original avgpool + flatten\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(1024, num_classes)\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:25.238154Z","iopub.execute_input":"2025-02-05T10:10:25.238434Z","iopub.status.idle":"2025-02-05T10:10:25.257661Z","shell.execute_reply.started":"2025-02-05T10:10:25.238407Z","shell.execute_reply":"2025-02-05T10:10:25.256960Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model = ButterflyCNN(num_classes=len(label_to_idx)).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:25.258462Z","iopub.execute_input":"2025-02-05T10:10:25.258719Z","iopub.status.idle":"2025-02-05T10:10:26.585284Z","shell.execute_reply.started":"2025-02-05T10:10:25.258699Z","shell.execute_reply":"2025-02-05T10:10:26.584355Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 214MB/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n# optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)  \noptimizer = torch.optim.Adam([\n    {'params': model.model.layer3.parameters(), 'lr': 1e-4},\n    {'params': model.model.layer4.parameters(), 'lr': 1e-4},\n    {'params': model.model.fc.parameters(), 'lr': 1e-3}\n])\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.5) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:26.586230Z","iopub.execute_input":"2025-02-05T10:10:26.586476Z","iopub.status.idle":"2025-02-05T10:10:26.591391Z","shell.execute_reply.started":"2025-02-05T10:10:26.586456Z","shell.execute_reply":"2025-02-05T10:10:26.590598Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### 训练函数 (>_<)","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    \n    for images, labels in loader:\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        total_loss += loss.item()\n        \n        _, predicted = torch.max(outputs, 1)\n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n    \n    # 计算指标\n    acc = np.mean(np.array(all_preds) == np.array(all_labels))\n    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n    avg_loss = total_loss / len(loader)\n    \n    return avg_loss, acc, balanced_acc\n\ndef train_model():\n    best_val_acc = 0\n    best_epoch = 0 \n    for epoch in range(EPOCHS):\n        # 训练阶段\n        model.train()\n        train_loss = 0.0\n        train_preds = []\n        train_labels = []\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n        for images, labels in progress_bar:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            inputs, targets_a, targets_b, lam = cutmix_data(images, labels, alpha=0.3)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, targets_a) * lam + criterion(outputs, targets_b) * (1. - lam)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            train_preds.extend(predicted.cpu().numpy())\n            train_labels.extend(labels.cpu().numpy())\n            \n            progress_bar.set_postfix(loss=train_loss / len(progress_bar))\n        \n        # 计算训练集指标\n        train_acc = np.mean(np.array(train_preds) == np.array(train_labels))\n        train_balanced_acc = balanced_accuracy_score(train_labels, train_preds)\n        train_loss = train_loss / len(train_loader)\n        \n        # 验证阶段\n        val_loss, val_acc, val_balanced_acc = evaluate(val_loader)\n        \n\n        \n        # 保存最佳模型\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_epoch = epoch\n            torch.save(model.state_dict(), 'best_model.pth')\n        \n        scheduler.step(val_acc) \n\n        if (epoch - best_epoch) >= 10:  # 连续5个epoch无提升\n            print(f\"Early stopping triggered at epoch {epoch+1}, best epoch: {best_epoch+1}\")\n            break\n                # 打印训练和验证指标\n        print(f\"\\nEpoch {epoch+1}/{EPOCHS}:\")\n        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Balanced Acc: {train_balanced_acc:.4f}\")\n        print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Balanced Acc: {val_balanced_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:26.593588Z","iopub.execute_input":"2025-02-05T10:10:26.593850Z","iopub.status.idle":"2025-02-05T10:10:26.608400Z","shell.execute_reply.started":"2025-02-05T10:10:26.593819Z","shell.execute_reply":"2025-02-05T10:10:26.607598Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"!pip install ttach","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:26.609221Z","iopub.execute_input":"2025-02-05T10:10:26.609456Z","iopub.status.idle":"2025-02-05T10:10:30.871387Z","shell.execute_reply.started":"2025-02-05T10:10:26.609425Z","shell.execute_reply":"2025-02-05T10:10:30.870246Z"}},"outputs":[{"name":"stdout","text":"Collecting ttach\n  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\nDownloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\nInstalling collected packages: ttach\nSuccessfully installed ttach-0.0.3\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### 预测函数 (^_^)","metadata":{}},{"cell_type":"code","source":"train_model()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:10:30.872599Z","iopub.execute_input":"2025-02-05T10:10:30.872943Z","iopub.status.idle":"2025-02-05T10:53:54.553537Z","shell.execute_reply.started":"2025-02-05T10:10:30.872909Z","shell.execute_reply":"2025-02-05T10:53:54.552644Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/100: 100%|██████████| 82/82 [00:49<00:00,  1.66it/s, loss=3.48] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/100:\nTrain - Loss: 3.4774, Acc: 0.1716, Balanced Acc: 0.1671\nVal   - Loss: 1.3528, Acc: 0.6338, Balanced Acc: 0.6243\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/100: 100%|██████████| 82/82 [00:36<00:00,  2.27it/s, loss=2.62] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/100:\nTrain - Loss: 2.6201, Acc: 0.3455, Balanced Acc: 0.3443\nVal   - Loss: 1.0517, Acc: 0.7108, Balanced Acc: 0.7081\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/100: 100%|██████████| 82/82 [00:34<00:00,  2.36it/s, loss=2.45] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/100:\nTrain - Loss: 2.4457, Acc: 0.4048, Balanced Acc: 0.4045\nVal   - Loss: 0.8222, Acc: 0.7815, Balanced Acc: 0.7789\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/100: 100%|██████████| 82/82 [00:34<00:00,  2.39it/s, loss=2.24] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/100:\nTrain - Loss: 2.2419, Acc: 0.4352, Balanced Acc: 0.4337\nVal   - Loss: 0.7148, Acc: 0.8138, Balanced Acc: 0.8122\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/100: 100%|██████████| 82/82 [00:34<00:00,  2.41it/s, loss=2.24] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/100:\nTrain - Loss: 2.2413, Acc: 0.4298, Balanced Acc: 0.4283\nVal   - Loss: 0.7279, Acc: 0.7985, Balanced Acc: 0.7974\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=2.11] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/100:\nTrain - Loss: 2.1091, Acc: 0.4621, Balanced Acc: 0.4602\nVal   - Loss: 0.6322, Acc: 0.8262, Balanced Acc: 0.8246\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/100: 100%|██████████| 82/82 [00:32<00:00,  2.52it/s, loss=2.18] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/100:\nTrain - Loss: 2.1798, Acc: 0.4848, Balanced Acc: 0.4840\nVal   - Loss: 0.6526, Acc: 0.8108, Balanced Acc: 0.8079\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/100: 100%|██████████| 82/82 [00:33<00:00,  2.47it/s, loss=2.08]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/100:\nTrain - Loss: 2.0796, Acc: 0.4898, Balanced Acc: 0.4881\nVal   - Loss: 0.5893, Acc: 0.8431, Balanced Acc: 0.8407\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=2.08] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/100:\nTrain - Loss: 2.0789, Acc: 0.4821, Balanced Acc: 0.4818\nVal   - Loss: 0.5538, Acc: 0.8308, Balanced Acc: 0.8294\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/100: 100%|██████████| 82/82 [00:33<00:00,  2.47it/s, loss=1.78]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/100:\nTrain - Loss: 1.7779, Acc: 0.5883, Balanced Acc: 0.5876\nVal   - Loss: 0.5067, Acc: 0.8738, Balanced Acc: 0.8706\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/100: 100%|██████████| 82/82 [00:33<00:00,  2.48it/s, loss=1.73] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11/100:\nTrain - Loss: 1.7314, Acc: 0.5748, Balanced Acc: 0.5732\nVal   - Loss: 0.4782, Acc: 0.8662, Balanced Acc: 0.8668\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/100: 100%|██████████| 82/82 [00:32<00:00,  2.51it/s, loss=1.92] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12/100:\nTrain - Loss: 1.9238, Acc: 0.4971, Balanced Acc: 0.4969\nVal   - Loss: 0.5652, Acc: 0.8523, Balanced Acc: 0.8494\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/100: 100%|██████████| 82/82 [00:32<00:00,  2.56it/s, loss=1.82]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13/100:\nTrain - Loss: 1.8167, Acc: 0.5683, Balanced Acc: 0.5670\nVal   - Loss: 0.4564, Acc: 0.8815, Balanced Acc: 0.8812\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/100: 100%|██████████| 82/82 [00:32<00:00,  2.54it/s, loss=1.75] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14/100:\nTrain - Loss: 1.7467, Acc: 0.5818, Balanced Acc: 0.5820\nVal   - Loss: 0.4978, Acc: 0.8738, Balanced Acc: 0.8723\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=1.73] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15/100:\nTrain - Loss: 1.7320, Acc: 0.5714, Balanced Acc: 0.5715\nVal   - Loss: 0.4774, Acc: 0.8892, Balanced Acc: 0.8877\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/100: 100%|██████████| 82/82 [00:32<00:00,  2.52it/s, loss=1.74] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16/100:\nTrain - Loss: 1.7435, Acc: 0.5933, Balanced Acc: 0.5943\nVal   - Loss: 0.4556, Acc: 0.8800, Balanced Acc: 0.8772\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/100: 100%|██████████| 82/82 [00:32<00:00,  2.53it/s, loss=1.74]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17/100:\nTrain - Loss: 1.7409, Acc: 0.5683, Balanced Acc: 0.5680\nVal   - Loss: 0.4237, Acc: 0.8892, Balanced Acc: 0.8892\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/100: 100%|██████████| 82/82 [00:32<00:00,  2.53it/s, loss=1.81] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18/100:\nTrain - Loss: 1.8128, Acc: 0.5491, Balanced Acc: 0.5482\nVal   - Loss: 0.4476, Acc: 0.8862, Balanced Acc: 0.8862\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/100: 100%|██████████| 82/82 [00:32<00:00,  2.53it/s, loss=1.7]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19/100:\nTrain - Loss: 1.6979, Acc: 0.5845, Balanced Acc: 0.5820\nVal   - Loss: 0.4860, Acc: 0.8738, Balanced Acc: 0.8708\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=1.66] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20/100:\nTrain - Loss: 1.6584, Acc: 0.5683, Balanced Acc: 0.5662\nVal   - Loss: 0.4175, Acc: 0.9000, Balanced Acc: 0.8991\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/100: 100%|██████████| 82/82 [00:32<00:00,  2.55it/s, loss=1.58] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 21/100:\nTrain - Loss: 1.5776, Acc: 0.6037, Balanced Acc: 0.6039\nVal   - Loss: 0.4147, Acc: 0.8954, Balanced Acc: 0.8939\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/100: 100%|██████████| 82/82 [00:33<00:00,  2.46it/s, loss=1.63] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 22/100:\nTrain - Loss: 1.6283, Acc: 0.5783, Balanced Acc: 0.5771\nVal   - Loss: 0.4681, Acc: 0.8785, Balanced Acc: 0.8748\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/100: 100%|██████████| 82/82 [00:32<00:00,  2.51it/s, loss=1.7]   \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23/100:\nTrain - Loss: 1.6974, Acc: 0.6022, Balanced Acc: 0.6024\nVal   - Loss: 0.4166, Acc: 0.8969, Balanced Acc: 0.8953\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/100: 100%|██████████| 82/82 [00:32<00:00,  2.51it/s, loss=1.71] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 24/100:\nTrain - Loss: 1.7128, Acc: 0.5802, Balanced Acc: 0.5789\nVal   - Loss: 0.4234, Acc: 0.9077, Balanced Acc: 0.9050\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/100: 100%|██████████| 82/82 [00:32<00:00,  2.52it/s, loss=1.71] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25/100:\nTrain - Loss: 1.7067, Acc: 0.5302, Balanced Acc: 0.5293\nVal   - Loss: 0.4280, Acc: 0.8954, Balanced Acc: 0.8938\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=1.55]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26/100:\nTrain - Loss: 1.5491, Acc: 0.6676, Balanced Acc: 0.6663\nVal   - Loss: 0.4524, Acc: 0.8985, Balanced Acc: 0.8957\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=1.47] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 27/100:\nTrain - Loss: 1.4659, Acc: 0.6772, Balanced Acc: 0.6775\nVal   - Loss: 0.4320, Acc: 0.9062, Balanced Acc: 0.9042\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/100: 100%|██████████| 82/82 [00:33<00:00,  2.43it/s, loss=1.64] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28/100:\nTrain - Loss: 1.6380, Acc: 0.6275, Balanced Acc: 0.6267\nVal   - Loss: 0.3620, Acc: 0.8969, Balanced Acc: 0.8935\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/100: 100%|██████████| 82/82 [00:33<00:00,  2.43it/s, loss=1.51] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29/100:\nTrain - Loss: 1.5075, Acc: 0.5902, Balanced Acc: 0.5902\nVal   - Loss: 0.4444, Acc: 0.9015, Balanced Acc: 0.9012\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/100: 100%|██████████| 82/82 [00:33<00:00,  2.45it/s, loss=1.62] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30/100:\nTrain - Loss: 1.6220, Acc: 0.6048, Balanced Acc: 0.6042\nVal   - Loss: 0.4105, Acc: 0.9015, Balanced Acc: 0.8988\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/100: 100%|██████████| 82/82 [00:33<00:00,  2.47it/s, loss=1.29] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 31/100:\nTrain - Loss: 1.2867, Acc: 0.6718, Balanced Acc: 0.6708\nVal   - Loss: 0.3444, Acc: 0.9154, Balanced Acc: 0.9127\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/100: 100%|██████████| 82/82 [00:33<00:00,  2.47it/s, loss=1.48] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 32/100:\nTrain - Loss: 1.4799, Acc: 0.6514, Balanced Acc: 0.6501\nVal   - Loss: 0.3533, Acc: 0.9215, Balanced Acc: 0.9192\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/100: 100%|██████████| 82/82 [00:32<00:00,  2.52it/s, loss=1.46] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 33/100:\nTrain - Loss: 1.4613, Acc: 0.6426, Balanced Acc: 0.6419\nVal   - Loss: 0.3820, Acc: 0.9123, Balanced Acc: 0.9094\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/100: 100%|██████████| 82/82 [00:33<00:00,  2.48it/s, loss=1.4]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 34/100:\nTrain - Loss: 1.4039, Acc: 0.6468, Balanced Acc: 0.6463\nVal   - Loss: 0.3304, Acc: 0.9200, Balanced Acc: 0.9175\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=1.32] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 35/100:\nTrain - Loss: 1.3235, Acc: 0.6695, Balanced Acc: 0.6690\nVal   - Loss: 0.3527, Acc: 0.9108, Balanced Acc: 0.9084\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=1.43]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 36/100:\nTrain - Loss: 1.4252, Acc: 0.6526, Balanced Acc: 0.6514\nVal   - Loss: 0.3415, Acc: 0.9262, Balanced Acc: 0.9245\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=1.35] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 37/100:\nTrain - Loss: 1.3499, Acc: 0.6933, Balanced Acc: 0.6936\nVal   - Loss: 0.3380, Acc: 0.9246, Balanced Acc: 0.9223\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=1.33]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 38/100:\nTrain - Loss: 1.3259, Acc: 0.6776, Balanced Acc: 0.6778\nVal   - Loss: 0.3433, Acc: 0.9292, Balanced Acc: 0.9267\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=1.21]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 39/100:\nTrain - Loss: 1.2081, Acc: 0.7487, Balanced Acc: 0.7486\nVal   - Loss: 0.3264, Acc: 0.9292, Balanced Acc: 0.9268\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=1.38] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 40/100:\nTrain - Loss: 1.3810, Acc: 0.6499, Balanced Acc: 0.6512\nVal   - Loss: 0.3538, Acc: 0.9200, Balanced Acc: 0.9172\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/100: 100%|██████████| 82/82 [00:33<00:00,  2.46it/s, loss=1.36] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 41/100:\nTrain - Loss: 1.3576, Acc: 0.6783, Balanced Acc: 0.6793\nVal   - Loss: 0.3489, Acc: 0.9215, Balanced Acc: 0.9189\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/100: 100%|██████████| 82/82 [00:33<00:00,  2.46it/s, loss=1.22] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 42/100:\nTrain - Loss: 1.2203, Acc: 0.6864, Balanced Acc: 0.6861\nVal   - Loss: 0.3372, Acc: 0.9292, Balanced Acc: 0.9269\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=1.44] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 43/100:\nTrain - Loss: 1.4412, Acc: 0.6048, Balanced Acc: 0.6038\nVal   - Loss: 0.3449, Acc: 0.9200, Balanced Acc: 0.9173\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/100: 100%|██████████| 82/82 [00:32<00:00,  2.51it/s, loss=1.25] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 44/100:\nTrain - Loss: 1.2550, Acc: 0.6868, Balanced Acc: 0.6859\nVal   - Loss: 0.3162, Acc: 0.9277, Balanced Acc: 0.9251\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=1.23] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 45/100:\nTrain - Loss: 1.2286, Acc: 0.6526, Balanced Acc: 0.6520\nVal   - Loss: 0.3108, Acc: 0.9262, Balanced Acc: 0.9239\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46/100: 100%|██████████| 82/82 [00:32<00:00,  2.49it/s, loss=1.26]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 46/100:\nTrain - Loss: 1.2604, Acc: 0.6637, Balanced Acc: 0.6634\nVal   - Loss: 0.3278, Acc: 0.9323, Balanced Acc: 0.9301\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47/100: 100%|██████████| 82/82 [00:33<00:00,  2.48it/s, loss=1.3]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 47/100:\nTrain - Loss: 1.2965, Acc: 0.6799, Balanced Acc: 0.6797\nVal   - Loss: 0.3080, Acc: 0.9323, Balanced Acc: 0.9302\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=1.24]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 48/100:\nTrain - Loss: 1.2395, Acc: 0.6653, Balanced Acc: 0.6641\nVal   - Loss: 0.3189, Acc: 0.9277, Balanced Acc: 0.9245\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49/100: 100%|██████████| 82/82 [00:33<00:00,  2.48it/s, loss=1.25] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 49/100:\nTrain - Loss: 1.2468, Acc: 0.6437, Balanced Acc: 0.6433\nVal   - Loss: 0.3127, Acc: 0.9338, Balanced Acc: 0.9313\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50/100: 100%|██████████| 82/82 [00:32<00:00,  2.53it/s, loss=1.24] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 50/100:\nTrain - Loss: 1.2351, Acc: 0.6518, Balanced Acc: 0.6511\nVal   - Loss: 0.3409, Acc: 0.9292, Balanced Acc: 0.9260\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51/100: 100%|██████████| 82/82 [00:33<00:00,  2.47it/s, loss=1.12] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 51/100:\nTrain - Loss: 1.1248, Acc: 0.6787, Balanced Acc: 0.6791\nVal   - Loss: 0.3167, Acc: 0.9323, Balanced Acc: 0.9296\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52/100: 100%|██████████| 82/82 [00:33<00:00,  2.48it/s, loss=1.11]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 52/100:\nTrain - Loss: 1.1124, Acc: 0.7060, Balanced Acc: 0.7053\nVal   - Loss: 0.3063, Acc: 0.9246, Balanced Acc: 0.9217\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53/100: 100%|██████████| 82/82 [00:32<00:00,  2.54it/s, loss=1.11]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 53/100:\nTrain - Loss: 1.1149, Acc: 0.6933, Balanced Acc: 0.6936\nVal   - Loss: 0.3247, Acc: 0.9323, Balanced Acc: 0.9292\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54/100: 100%|██████████| 82/82 [00:32<00:00,  2.53it/s, loss=1.15] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 54/100:\nTrain - Loss: 1.1534, Acc: 0.7087, Balanced Acc: 0.7083\nVal   - Loss: 0.3113, Acc: 0.9308, Balanced Acc: 0.9283\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55/100: 100%|██████████| 82/82 [00:32<00:00,  2.54it/s, loss=1.23] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 55/100:\nTrain - Loss: 1.2333, Acc: 0.6679, Balanced Acc: 0.6679\nVal   - Loss: 0.3072, Acc: 0.9323, Balanced Acc: 0.9296\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56/100: 100%|██████████| 82/82 [00:32<00:00,  2.55it/s, loss=1.26] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 56/100:\nTrain - Loss: 1.2630, Acc: 0.6260, Balanced Acc: 0.6266\nVal   - Loss: 0.3045, Acc: 0.9369, Balanced Acc: 0.9351\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57/100: 100%|██████████| 82/82 [00:32<00:00,  2.56it/s, loss=1.12] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 57/100:\nTrain - Loss: 1.1166, Acc: 0.6903, Balanced Acc: 0.6901\nVal   - Loss: 0.3021, Acc: 0.9354, Balanced Acc: 0.9325\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58/100: 100%|██████████| 82/82 [00:33<00:00,  2.48it/s, loss=1.26] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 58/100:\nTrain - Loss: 1.2639, Acc: 0.6333, Balanced Acc: 0.6332\nVal   - Loss: 0.3015, Acc: 0.9338, Balanced Acc: 0.9304\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59/100: 100%|██████████| 82/82 [00:33<00:00,  2.48it/s, loss=1.11]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 59/100:\nTrain - Loss: 1.1060, Acc: 0.7276, Balanced Acc: 0.7267\nVal   - Loss: 0.2941, Acc: 0.9338, Balanced Acc: 0.9311\n","output_type":"stream"},{"name":"stderr","text":"Epoch 60/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=1.15]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 60/100:\nTrain - Loss: 1.1546, Acc: 0.7083, Balanced Acc: 0.7079\nVal   - Loss: 0.3026, Acc: 0.9338, Balanced Acc: 0.9315\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61/100: 100%|██████████| 82/82 [00:33<00:00,  2.47it/s, loss=1.23] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 61/100:\nTrain - Loss: 1.2330, Acc: 0.6841, Balanced Acc: 0.6853\nVal   - Loss: 0.2904, Acc: 0.9385, Balanced Acc: 0.9363\n","output_type":"stream"},{"name":"stderr","text":"Epoch 62/100: 100%|██████████| 82/82 [00:32<00:00,  2.52it/s, loss=1.18] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 62/100:\nTrain - Loss: 1.1764, Acc: 0.6591, Balanced Acc: 0.6578\nVal   - Loss: 0.2999, Acc: 0.9338, Balanced Acc: 0.9312\n","output_type":"stream"},{"name":"stderr","text":"Epoch 63/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=1.06] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 63/100:\nTrain - Loss: 1.0589, Acc: 0.6980, Balanced Acc: 0.6973\nVal   - Loss: 0.2871, Acc: 0.9415, Balanced Acc: 0.9401\n","output_type":"stream"},{"name":"stderr","text":"Epoch 64/100: 100%|██████████| 82/82 [00:32<00:00,  2.53it/s, loss=1.16] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 64/100:\nTrain - Loss: 1.1615, Acc: 0.6622, Balanced Acc: 0.6611\nVal   - Loss: 0.2885, Acc: 0.9338, Balanced Acc: 0.9312\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65/100: 100%|██████████| 82/82 [00:33<00:00,  2.48it/s, loss=1.22] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 65/100:\nTrain - Loss: 1.2231, Acc: 0.6549, Balanced Acc: 0.6533\nVal   - Loss: 0.2867, Acc: 0.9400, Balanced Acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66/100: 100%|██████████| 82/82 [00:32<00:00,  2.54it/s, loss=1.09] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 66/100:\nTrain - Loss: 1.0927, Acc: 0.6795, Balanced Acc: 0.6790\nVal   - Loss: 0.2952, Acc: 0.9323, Balanced Acc: 0.9300\n","output_type":"stream"},{"name":"stderr","text":"Epoch 67/100: 100%|██████████| 82/82 [00:32<00:00,  2.55it/s, loss=1.16]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 67/100:\nTrain - Loss: 1.1568, Acc: 0.6422, Balanced Acc: 0.6428\nVal   - Loss: 0.2909, Acc: 0.9338, Balanced Acc: 0.9317\n","output_type":"stream"},{"name":"stderr","text":"Epoch 68/100: 100%|██████████| 82/82 [00:32<00:00,  2.53it/s, loss=1.12] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 68/100:\nTrain - Loss: 1.1208, Acc: 0.7134, Balanced Acc: 0.7135\nVal   - Loss: 0.2960, Acc: 0.9369, Balanced Acc: 0.9344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 69/100: 100%|██████████| 82/82 [00:32<00:00,  2.54it/s, loss=1.13]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 69/100:\nTrain - Loss: 1.1332, Acc: 0.6876, Balanced Acc: 0.6873\nVal   - Loss: 0.2926, Acc: 0.9338, Balanced Acc: 0.9313\n","output_type":"stream"},{"name":"stderr","text":"Epoch 70/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=1.04] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 70/100:\nTrain - Loss: 1.0396, Acc: 0.7784, Balanced Acc: 0.7786\nVal   - Loss: 0.2856, Acc: 0.9369, Balanced Acc: 0.9346\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71/100: 100%|██████████| 82/82 [00:33<00:00,  2.47it/s, loss=1.17] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 71/100:\nTrain - Loss: 1.1734, Acc: 0.6837, Balanced Acc: 0.6841\nVal   - Loss: 0.2771, Acc: 0.9354, Balanced Acc: 0.9330\n","output_type":"stream"},{"name":"stderr","text":"Epoch 72/100: 100%|██████████| 82/82 [00:32<00:00,  2.50it/s, loss=1.05]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 72/100:\nTrain - Loss: 1.0484, Acc: 0.7661, Balanced Acc: 0.7660\nVal   - Loss: 0.2778, Acc: 0.9354, Balanced Acc: 0.9327\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73/100: 100%|██████████| 82/82 [00:33<00:00,  2.48it/s, loss=1.15]  \n","output_type":"stream"},{"name":"stdout","text":"Early stopping triggered at epoch 73, best epoch: 63\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# 在导入库部分添加ttach\nimport ttach as tta\n\n# 修改后的预测函数（保持原函数名称不变）\n@torch.no_grad()\ndef predict():\n    # 加载最佳模型\n    model.load_state_dict(torch.load('best_model.pth'))\n    model.eval()\n    \n    # 创建TTA包装模型（分类任务）\n    tta_model = tta.ClassificationTTAWrapper(\n        model,\n        tta.aliases.five_crop_transform(crop_height=224, crop_width=224),\n        merge_mode=\"mean\"  # 几何平均效果更好\n    )\n    \n    predictions = []\n    for images, img_names in tqdm(test_loader, desc=\"TTA Predicting\"):\n        images = images.to(DEVICE)\n        \n        # 使用TTA模型预测\n        outputs = tta_model(images)\n        \n        # 获取预测结果\n        _, predicted = torch.max(outputs, 1)\n        predicted_labels = [idx_to_label[idx.item()] for idx in predicted]\n        predictions.extend(zip(img_names, predicted_labels))\n    \n    return predictions\n\n# 保存函数无需修改\ndef save_predictions(predictions):\n    submission_df = pd.DataFrame(predictions, columns=['filename', 'label'])\n    submission_df.to_csv(SUBMISSION_FILE, index=False)\n\n# 执行预测（保持调用方式不变）\npredictions = predict()\nsave_predictions(predictions)\nprint(f\"Submission file saved as {SUBMISSION_FILE}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:19:14.628093Z","iopub.execute_input":"2025-02-05T11:19:14.628400Z","iopub.status.idle":"2025-02-05T11:19:48.126706Z","shell.execute_reply.started":"2025-02-05T11:19:14.628380Z","shell.execute_reply":"2025-02-05T11:19:48.125983Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-18-77ab5f10ba84>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_model.pth'))\nTTA Predicting: 100%|██████████| 102/102 [00:33<00:00,  3.06it/s]","output_type":"stream"},{"name":"stdout","text":"Submission file saved as /kaggle/working/submission.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18}]}